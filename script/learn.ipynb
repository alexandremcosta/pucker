{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('../db/pucker.sqlite3')\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM states\", conn)\n",
    "df = df.loc[:, 'total_players':'reward'] # Remove ID\n",
    "\n",
    "df_flop = df[df.turn_rank.isnull() & df.river_rank.isnull()]\n",
    "df_flop = df_flop.drop(['turn_rank', 'turn_suit', 'river_rank', 'river_suit'], axis=1)\n",
    "\n",
    "Xflop = df_flop.loc[:, 'total_players':'decision_raise']\n",
    "yflop = df_flop.loc[:, 'reward']\n",
    "yflop = pd.DataFrame([1 if item > 0 else 0 for item in yflop])\n",
    "\n",
    "df_turn = df[df.turn_rank.notnull() & df.river_rank.isnull()]\n",
    "df_turn = df_turn.drop(['river_rank', 'river_suit'], axis=1)\n",
    "\n",
    "Xturn = df_turn.loc[:, 'total_players':'decision_raise']\n",
    "yturn = df_turn.loc[:, 'reward']\n",
    "\n",
    "df_river = df[df.turn_rank.notnull() & df.river_rank.notnull()]\n",
    "\n",
    "Xriver = df_river.loc[:, 'total_players':'decision_raise']\n",
    "yriver = df_river.loc[:, 'reward']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Encode and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "def diff(first, second):\n",
    "    first = list(first)\n",
    "    second = list(second)\n",
    "    return [item for item in first if item not in second]\n",
    "\n",
    "def process(data):\n",
    "    encode_columns = [item for item in data.columns if 'suit' in item]\n",
    "    scale_columns = diff(data.columns, encode_columns)\n",
    "\n",
    "    column_transformer = make_column_transformer(\n",
    "        (StandardScaler(), scale_columns),\n",
    "        (OneHotEncoder(categories='auto'), encode_columns))\n",
    "\n",
    "    return column_transformer.fit_transform(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def neural_network(nfeatures):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_dim=nfeatures, units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='tanh', kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(units=1000, activation='tanh', kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(units=1, activation='linear', kernel_initializer='random_normal'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def flop_neural_network(nfeatures):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_dim=nfeatures, units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='tanh', kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(units=1000, activation='tanh', kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "211956/211956 [==============================] - 17s 81us/step - loss: 0.7161 - acc: 0.7440 - mean_absolute_error: 0.3016\n",
      "Epoch 2/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3416 - acc: 0.7983 - mean_absolute_error: 0.2401\n",
      "Epoch 3/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3361 - acc: 0.8051 - mean_absolute_error: 0.2362\n",
      "Epoch 4/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3326 - acc: 0.8121 - mean_absolute_error: 0.2328\n",
      "Epoch 5/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3290 - acc: 0.8177 - mean_absolute_error: 0.2298\n",
      "Epoch 6/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3250 - acc: 0.8209 - mean_absolute_error: 0.2257\n",
      "Epoch 7/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3234 - acc: 0.8235 - mean_absolute_error: 0.2246\n",
      "Epoch 8/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3181 - acc: 0.8276 - mean_absolute_error: 0.2208\n",
      "Epoch 9/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3188 - acc: 0.8267 - mean_absolute_error: 0.2199\n",
      "Epoch 10/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.3115 - acc: 0.8320 - mean_absolute_error: 0.2151\n",
      "Epoch 11/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.3110 - acc: 0.8335 - mean_absolute_error: 0.2137\n",
      "Epoch 12/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.3034 - acc: 0.8393 - mean_absolute_error: 0.2084\n",
      "Epoch 13/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3011 - acc: 0.8410 - mean_absolute_error: 0.2053\n",
      "Epoch 14/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2983 - acc: 0.8438 - mean_absolute_error: 0.2029\n",
      "Epoch 15/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2852 - acc: 0.8537 - mean_absolute_error: 0.1937\n",
      "Epoch 16/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2929 - acc: 0.8516 - mean_absolute_error: 0.1976\n",
      "Epoch 17/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2794 - acc: 0.8593 - mean_absolute_error: 0.1893\n",
      "Epoch 18/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2703 - acc: 0.8658 - mean_absolute_error: 0.1816\n",
      "Epoch 19/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2528 - acc: 0.8778 - mean_absolute_error: 0.1667\n",
      "Epoch 20/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3209 - acc: 0.8300 - mean_absolute_error: 0.2097\n",
      "Epoch 21/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.3057 - acc: 0.8386 - mean_absolute_error: 0.2119\n",
      "Epoch 22/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.2750 - acc: 0.8623 - mean_absolute_error: 0.1849\n",
      "Epoch 23/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.2783 - acc: 0.8611 - mean_absolute_error: 0.1851\n",
      "Epoch 24/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.2396 - acc: 0.8868 - mean_absolute_error: 0.1600\n",
      "Epoch 25/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.2163 - acc: 0.8997 - mean_absolute_error: 0.1401\n",
      "Epoch 26/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.2038 - acc: 0.9066 - mean_absolute_error: 0.1318\n",
      "Epoch 27/50\n",
      "211956/211956 [==============================] - 16s 73us/step - loss: 0.1851 - acc: 0.9175 - mean_absolute_error: 0.1164\n",
      "Epoch 28/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.1757 - acc: 0.9220 - mean_absolute_error: 0.1130\n",
      "Epoch 29/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.1577 - acc: 0.9312 - mean_absolute_error: 0.0996\n",
      "Epoch 30/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.1380 - acc: 0.9410 - mean_absolute_error: 0.0846\n",
      "Epoch 31/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.1206 - acc: 0.9494 - mean_absolute_error: 0.0759\n",
      "Epoch 32/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.1079 - acc: 0.9556 - mean_absolute_error: 0.0655\n",
      "Epoch 33/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0972 - acc: 0.9603 - mean_absolute_error: 0.0583\n",
      "Epoch 34/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0882 - acc: 0.9643 - mean_absolute_error: 0.0535\n",
      "Epoch 35/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0702 - acc: 0.9726 - mean_absolute_error: 0.0421\n",
      "Epoch 36/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0675 - acc: 0.9733 - mean_absolute_error: 0.0394\n",
      "Epoch 37/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0605 - acc: 0.9766 - mean_absolute_error: 0.0359\n",
      "Epoch 38/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0540 - acc: 0.9791 - mean_absolute_error: 0.0318\n",
      "Epoch 39/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0455 - acc: 0.9828 - mean_absolute_error: 0.0265\n",
      "Epoch 40/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0438 - acc: 0.9837 - mean_absolute_error: 0.0252\n",
      "Epoch 41/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0423 - acc: 0.9841 - mean_absolute_error: 0.0239\n",
      "Epoch 42/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0412 - acc: 0.9848 - mean_absolute_error: 0.0235\n",
      "Epoch 43/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0403 - acc: 0.9851 - mean_absolute_error: 0.0232\n",
      "Epoch 44/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0297 - acc: 0.9892 - mean_absolute_error: 0.0169\n",
      "Epoch 45/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0292 - acc: 0.9894 - mean_absolute_error: 0.0163\n",
      "Epoch 46/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0239 - acc: 0.9915 - mean_absolute_error: 0.0134\n",
      "Epoch 47/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0248 - acc: 0.9911 - mean_absolute_error: 0.0137\n",
      "Epoch 48/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0235 - acc: 0.9920 - mean_absolute_error: 0.0130\n",
      "Epoch 49/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0248 - acc: 0.9912 - mean_absolute_error: 0.0134\n",
      "Epoch 50/50\n",
      "211956/211956 [==============================] - 15s 73us/step - loss: 0.0223 - acc: 0.9919 - mean_absolute_error: 0.0126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = process(Xflop)\n",
    "y = yflop.values\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "nfeatures = X.shape[1]\n",
    "model = flop_neural_network(nfeatures)\n",
    "model.fit(Xtrain, ytrain, batch_size=10000, epochs=50) # 20 for flop 100 for river\n",
    "ypred = model.predict(Xtest)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix:\n",
      "[[36208  5900]\n",
      " [ 5439  5442]]\n",
      "\n",
      "Loss classified as loss 36208\n",
      "Wins classified as wins 5442\n",
      "Wins classified as loss 5439\n",
      "Loss classified as wins 5900\n",
      "\n",
      "Accuracy:\t 0.7860121912094963\n",
      "Precision:\t 0.4798095573972844\n",
      "Recall: \t 0.5001378549765646\n",
      "F1 score:\t 0.48976285829995947\n",
      "Mean abs error:  0.21494969869031577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
    "\n",
    "ytest_classification = [1 if item > 0.5 else 0 for item in ytest]\n",
    "ypred_classification = [1 if item > 0.5 else 0 for item in ypred]\n",
    "\n",
    "cm = confusion_matrix(ytest_classification, ypred_classification)\n",
    "print('\\nConfusion matrix:')\n",
    "print(cm)\n",
    "print(\"\\nLoss classified as loss\", cm[0][0])\n",
    "print(\"Wins classified as wins\", cm[1][1])\n",
    "print(\"Wins classified as loss\", cm[1][0])\n",
    "print(\"Loss classified as wins\", cm[0][1])\n",
    "print('\\nAccuracy:\\t', accuracy_score(ytest_classification, ypred_classification))\n",
    "print('Precision:\\t', precision_score(ytest_classification, ypred_classification))\n",
    "print('Recall: \\t', recall_score(ytest_classification, ypred_classification))\n",
    "print('F1 score:\\t', f1_score(ytest_classification, ypred_classification))\n",
    "print('Mean abs error: ', mean_absolute_error(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model in h5 format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"pucker.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
