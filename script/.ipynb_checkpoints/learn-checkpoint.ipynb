{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('../db/pucker.sqlite3')\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM states\", conn)\n",
    "df = df.loc[:, 'total_players':'reward'] # Remove ID\n",
    "\n",
    "df_flop = df[df.turn_rank.isnull() & df.river_rank.isnull()]\n",
    "df_flop = df_flop.drop(['turn_rank', 'turn_suit', 'river_rank', 'river_suit'], axis=1)\n",
    "df_flop = df_flop[df_flop.position_over_all > 2]\n",
    "df_turn = df[df.turn_rank.notnull() & df.river_rank.isnull()]\n",
    "df_turn = df_turn.drop(['river_rank', 'river_suit'], axis=1)\n",
    "df_river = df[df.turn_rank.notnull() & df.river_rank.notnull()]\n",
    "\n",
    "Xflop = df_flop.loc[:, 'total_players':'decision_raise']\n",
    "yflop = df_flop.loc[:, 'reward']\n",
    "yflop = pd.DataFrame([1 if item > 0 else 0 for item in yflop])\n",
    "Xturn = df_turn.loc[:, 'total_players':'decision_raise']\n",
    "yturn = df_turn.loc[:, 'reward']\n",
    "Xriver = df_river.loc[:, 'total_players':'decision_raise']\n",
    "yriver = df_river.loc[:, 'reward']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def neural_network(nfeatures):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_dim=nfeatures, units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=1000, activation='tanh', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dense(units=1000, activation='tanh', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dense(units=1, activation='linear', kernel_initializer='random_normal'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def flop_neural_network(nfeatures):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_dim=nfeatures, units=2000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=2000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=2000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=2000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=2000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=2000, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(units=2000, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Encode and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "def diff(first, second):\n",
    "    first = list(first)\n",
    "    second = list(second)\n",
    "    return [item for item in first if item not in second]\n",
    "\n",
    "def process(data):\n",
    "    encode_columns = [item for item in data.columns if 'suit' in item]\n",
    "    scale_columns = diff(data.columns, encode_columns)\n",
    "\n",
    "    column_transformer = make_column_transformer(\n",
    "        (StandardScaler(), scale_columns),\n",
    "        (OneHotEncoder(categories='auto'), encode_columns))\n",
    "\n",
    "    return column_transformer.fit_transform(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = process(Xflop)\n",
    "y = yflop.values\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "nfeatures = X.shape[1]\n",
    "model = flop_neural_network(nfeatures)\n",
    "model.fit(Xtrain, ytrain, batch_size=5000, epochs=30)\n",
    "ypred = model.predict(Xtest)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96ed6c51e7c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mytest_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mypred_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ytest' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
    "\n",
    "ytest_classification = [1 if item > 0.5 else 0 for item in ytest]\n",
    "ypred_classification = [1 if item > 0.5 else 0 for item in ypred]\n",
    "\n",
    "cm = confusion_matrix(ytest_classification, ypred_classification)\n",
    "print('\\nConfusion matrix:')\n",
    "print(cm)\n",
    "print(\"\\nLoss classified as loss\", cm[0][0])\n",
    "print(\"Wins classified as wins\", cm[1][1])\n",
    "print(\"Wins classified as loss\", cm[1][0])\n",
    "print(\"Loss classified as wins\", cm[0][1])\n",
    "print('\\nAccuracy:\\t', accuracy_score(ytest_classification, ypred_classification))\n",
    "print('Precision:\\t', precision_score(ytest_classification, ypred_classification))\n",
    "print('Recall: \\t', recall_score(ytest_classification, ypred_classification))\n",
    "print('F1 score:\\t', f1_score(ytest_classification, ypred_classification))\n",
    "print('Mean abs error: ', mean_absolute_error(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model in h5 format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"pucker.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
